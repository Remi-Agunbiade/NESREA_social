---
title: "Weekly Web Monitoring Report"
author: "NESREA Web Monitoring Group"
output:
  word_document: default
---
<style>
  body {
    text-align: justify
  }
</style>                                                                  
<!--

  *****************************************************************************
  *                         GENERAL NOTICE                                    *
  * This is a generic reporting format for the NESREA Web Monitoring Group.   *
  *                       http://www.nesrea.gov.ng                            *
  *          It is an open source project. See LICENSE for details.           *
  *****************************************************************************
                                                                           -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r initialize, message=FALSE, include=FALSE}
## The existence of required dependencies is checked for. If absent, these are
## automatically downloaded and installed. Then, packages are (quietly) loaded.
## Where there's an issue in R-3.2.4
## See https://stackoverflow.com/questions/39885408/dependency-slam-is-not-available-when-installing-tm-package
cran_mirror <- "https://cran.rstudio.com"
pkglist <- c("DBI",
             "RSQLite",
             "Rfacebook",
             "dplyr",
             "ggplot2",
             "lubridate",
             "qdap",
             "rvest",
             "slam",
             "SnowballC",
             "stringr",
             "tm",
             "twitteR",
             "wordcloud")

if (getRversion() == "3.2.3" && !requireNamespace("devtools")) {
  slam_url <- 
  "https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
  install.packages("devtools", repos = cran_mirror)
  devtools::install_url(slam_url)
}

not_installed <- pkglist[!pkglist %in% (.packages(all.available = TRUE))]
if (length(not_installed))
  install.packages(not_installed, repos = cran_mirror)
suppressPackageStartupMessages(lapply(pkglist, library, character.only = TRUE))

source("global-function-prototypes.R")
source_but_also_check_for(c("../twitter/tw-functions.R",
                            "../facebook/fb-functions.R"))
report.period.text <- paste(format(today() - 6, "%d %B"),
                          "to",
                          format(today(), "%d %B %Y"))
rm(source_but_also_check_for, pkglist, not_installed)
```

# 1.0 Introduction
This is the NESREA Web Monitoring Report for the period **`r report.period.text`**[^1].

# 2.0 Summary Statistics
The following tables provide an overview of activity on the Agency's respective platforms.  

## 2.1 NESREA Official Website
```{r load website data}
                        ############
                        # Website  #
                        ############

connection <- dbConnect(SQLite(), "../data/nesreanigeria.db")
newsData <- dbReadTable(connection, "nesreanigeria_webnews")
dbDisconnect(connection); rm(connection)

newsData$Date <- newsData$Date %>%
  as.Date(origin = "1970-01-01") %>%
  as.POSIXct()

newsData <- newsData %>%
  mutate(Month = format(Date, "%B")) %>%
  mutate(Year = format(Date, "%Y"))

## make variables for monthly/annual data
thisMth <- format(today(), "%B")
thisYr <- format(today(), "%Y")

mth_news <- newsData %>%
  filter(Month == thisMth & Year == thisYr)
wk_news <- newsData %>%
  filter(as.Date(Date) >= today() - 7)
```

|     **Description**        |    **Result**                              |
|----------------------------|--------------------------------------------|
|News Stories (All-time)     |`r nrow(newsData)`                          |
|News Stories in `r thisMth` |`r nrow(mth_news)`                          |
|News Stories (last 7 days)  |`r nrow(wk_news)`                           |
|Most recent News Story      |`r newsData$Title[which.max(newsData$Date)]`|
|                            |                                            |

## 2.2 Twitter
```{r load twitter data, message=FALSE}
                      ##############
                      #  TWITTER   #
                      ##############
## Access stored tweets
register_sqlite_backend("../data/nesreanigeria.db") 
all_data <- load_tweets_db(as.data.frame = TRUE, "nesreanigeria_tweets")


## Add a column of Date objects for easy categorisation. Also carry out a 
## check to see whether the database needs to be updated.
all_data$date_only <- as.Date(all_data$created)

wk_data <- all_data %>%
  filter(date_only >= (today() - 6) & date_only <= (today())) %>%
  arrange(date_only) %>%
  mutate(day = weekdays(date_only, abbreviate = TRUE)) %>%
  mutate(Type = ifelse(isRetweet, "Retweet", "Original"))
wk_data$day <-  factor(wk_data$day,
                       levels = unique(wk_data$day),
                       ordered = TRUE)
  
last_wk <- all_data %>%
  filter(date_only >= (today() - 13) & date_only <= (today() - 7))

## Remove characters from the text of tweets that are not human-readable, as 
## they would be of no practical use in the analysis.
wk_data$text <- remove_nonreadables(wk_data$text)

# Some objects to be used to generate and/or display statistics
no.wk <- nrow(wk_data)
month_begin <- floor_date(today(), "month")
month_end <- ceiling_date(today(), "month")
mth_data <- filter(all_data, date_only >= month_begin & date_only <= month_end)
mostRTed <- wk_data$text[which.max(wk_data$retweetCount)]
mostFaved <- wk_data$text[which.max(wk_data$favoriteCount)]
tweets_by_us <- filter(wk_data, screenName == "NESREANigeria")
busiest_day <- which.max(table(wk_data$date_only))
busiest_day <- ymd(names(busiest_day))
```

|     **Description**                      |    **Result**                  |
|------------------------------------------|--------------------------------|
|No. of tweets in `r format(today(), "%B")`|`r nrow(mth_data)`              |
|No. of tweets in last 7 days              |`r no.wk`                       |
|Total tweets **by** NESREA                |`r nrow(tweets_by_us)`          |
|Total tweets **mentioning** NESREA        |`r nrow(wk_data)`               |
|Average number of tweets per day          |`r floor(nrow(wk_data)/7)`      |
|Day of highest activity                   |`r format(busiest_day, "%d %B")`|
|Most liked tweet                          |`r mostFaved`                   |
|Most retweeted tweet                      |`r mostRTed`                    |
|Comparative tweet volume (week-on-week)   |**`r no.wk - nrow(last_wk)`**   |
|                                          |                                |

<!-- TODO: Add No. of followers (overall) & new followers (in last 7 days) -->

## 2.3 Facebook
```{r load-fb-data, message=FALSE}
                        ############
                        # Facebook #
                        ############
## Load data on Facebook Page posts from database;
## also do a little data wrangling
connxn <- dbConnect(SQLite(), "../data/nesreanigeria.db")

fbPosts <- dbGetQuery(connxn, 'SELECT * FROM nesreanigeria_fbposts') %>%
  prepare_data(.) %>%
  select(message:shares_count) %>%
  mutate(created_mth = format(as.Date(created_time), "%B")) %>%
  mutate(created_yr = format(as.Date(created_time), "%Y"))


fbComments <- dbReadTable(connxn, "nesreanigeria_fbcomments")
fbLikes <- dbReadTable(connxn, "nesreanigeria_fblikes")

dbDisconnect(connxn)
rm(connxn)

## Convert to date-time structures
fbPosts$created_time <- as.POSIXct(fbPosts$created_time)
fbComments$created_time <- as.POSIXct(fbComments$created_time)

## Remove any non-humanly readable characters
fbPosts$message <- remove_nonreadables(fbPosts$message)
fbComments$message <- remove_nonreadables(fbComments$message)

fbPosts$created_mth <-
  fbPosts$created_mth %>%
  factor(levels = month.name, ordered = TRUE)

mth_Posts <- fbPosts %>%
  filter(created_mth == thisMth & created_yr == thisYr)
wk_Posts <- mth_Posts %>%
  filter(created_time >= (today() - 6))
```

|     **Description**        |    **Result**                            |
|----------------------------|------------------------------------------|
|NESREA Page Posts (All-time)|`r nrow(fbPosts)`                         |
|Posts in `r thisMth`        |`r nrow(mth_Posts)`                       |
|Posts in the past 7 days    |`r nrow(wk_Posts)`                        |
|Most Liked  (Overall)       |`r return_text(fbPosts, "likes_count")`   |
|Most Liked in `r thisMth`   |`r return_text(mth_Posts, "likes_count")` |
|Most Shared (Overall)       |`r return_text(fbPosts, "shares_count")`  |
|Most Shared in `r thisMth`  |`r return_text(mth_Posts, "shares_count")`|
|Most Commented  (Overall)   |`r return_text(fbPosts, "comments_count")`|
|                            |                                          |

# 3.0 Exploratory Analysis
**Methodology**: The data were harvested using R scripts[^2]. For the website, the text in the pages of interest were scraped as hypertext markup language (HTML) with particular portions of the page(s) identified via cascading style sheet (CSS) selectors. For the social media platforms Facebook and Twitter, the data were downloaded via the respective platforms' application programming interface (API). All the downloaded data are stored together locally in a database. The analyses in this document (including visualizations) were also carried out using R.

## 3.1 Website 
Below is a tabulation of recent news items uploaded to the NESREA Official website:
```{r news summary, results='asis'}
knitr::kable(head(newsData[, c(1, 4, 5)], n = 10L),
             caption = "Table: Ten (10) Most Recently Uploaded News Stories")
```

## 3.2 Twitter
All tweets in this analysis are those containing the NESREA handle, [nesreanigeria](https://www.twitter.com/nesreanigeria). Firstly, they are displayed as a density distribution, where $p(AUC) = 1$ (for simplicity, the $y$-axis labels are not displayed).  
```{r plain density, warning=FALSE, message=FALSE}
simplePlot <- plain_dens_plot(data = wk_data, platform = "twitter")
simplePlot +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

Below, is a representation of the previous plot, with the data disaggregated by days in order to display relative Twitter activity during the week under review.[^3]  
```{r daily tweets plot}  
simplePlot +
  facet_grid(day ~ .) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

The tweets are then diaggregated by whether they are original tweets or retweets (retweets could be reflective of a trend or public interest in a particular tweet posted by another user).  
```{r disaggregated tweets density}
ggplot(wk_data, aes(created)) +
  geom_density(aes(fill = Type), alpha = .5) +
  theme(legend.justification = c(1, 1), legend.position = c(1, 1)) +
  ggtitle(paste("Distribution of tweets for", report.period.text)) +
  xlab("Date")
```

For sentiment analysis, positive and negative words are displayed in Cleveland dot plots  
```{r twitter sentiments dotchart-1}
spl <- split(wk_data, wk_data$isRetweet)
origTwts <- spl[['FALSE']]

twPol <- compute_emotional_valence(origTwts$text)
visualise_pol_diff(pol.list = twPol)
```


```{r twitter sentiment extremes}
origTwts$emotionalValence <- sapply(twPol, function(x) x$all$polarity)
```

The tweets on either side of the emotional spectrum are identified. This is done to place the outcome of the earlier computaion in proper perspective.

* __Most positive tweet__: `r origTwts$text[which.max(origTwts$emotionalValence)]`
* __Most negative tweet__: `r origTwts$text[which.min(origTwts$emotionalValence)]`  

The main words associated with tweets found to be positive, neutral or negative (excluding those already plotted above) are displayed in a tag cloud. In this depiction, the size of a word is proportionate to the frequency of its occurence. These can be useful as keywords for carrying out a further, in-depth search.   
```{r, twitter wordcloud}
generate_wordcloud(origTwts, twPol, site = "Twitter")
```

```{r network}
## TODO
RT <- mutate(spl[['TRUE']], sender = substr(text, 5, regexpr(':', text) - 1))
```


## 3.3 Facebook
Compared to Twitter, which has a characteristic high-volume activity, NESREA Facebook Page posts are few. Thus, we have drawn a Kernig density plot of **all** posts done by the Page's handlers.  
```{r density dist: FB posts}
ggplot(fbPosts, aes(created_time)) +
  geom_density(fill = "purple", alpha = 0.6) +
  ggtitle("Distribution of Facebook posts")
```

Also, all comments made on NESREA's Facebook Page posts are displayed using a similar plotting method.  
```{r density dist: FB comments}
plain_dens_plot(fbComments, platform = "facebook")
```

As with the Twitter data, the positive and negative words on in comments on the NESREA Facebook Page are compared side-by-side using Cleveland dot plots.  
```{r fb polarities}
fbPol <- compute_emotional_valence(text.var = fbComments$message)
visualise_pol_diff(pol.list = fbPol)
```

The tag cloud method is also used to present key words found in comments made by the Facebook community on the Agency's posts.  
```{r facebook wordcloud}
fbComments$emotionalValence <- sapply(fbPol, function(x) x$all$polarity)
generate_wordcloud(fbComments, fbPol, site = "Facebook")
```

# 4.0 Observations
For the period under review, the following observations were made:  
**Website:**


**Twitter:**  


**Facebook:**  

# 5.0 Recommendations
In the light of the above, we would like to make the following recommendations:  


```{r signatories, echo=FALSE}
victor <- person("Victor", "Ordu", email =  "victor.ordu@nesrea.gov.ng", comment = "Chairman Web Monitoring Group")
remi <- person("Remi", "Agunbiade", email = "remi.agunbiade@nesrea.gov.ng", comment = "Member, Web Monitoring Group")
amaka <- person("Amaka", "Ejiofor", email = "amaka.ejiofor@nesrea.gov.ng", comment = "Member, Web Monitoring Group")
eze <- person("Ezechinyere", "Achilefu", email = "ezechinyere.achilefu@nesrea.gov.ng", comment = "Member, Web Monitoring Group")
```

Submitted by:


**`r paste(victor$given, victor$family)`**  
`r victor$comment`  

  
[^1]: The report was built using *R `r getRversion()`* on `r format(Sys.time(), "%A, %d %B %Y at %H:%M")`.
[^2]: R is a programming language as well as an environment for statistical computing (<http://r-project.org>)
[^3]: Note that days with no data are automatically dropped.
